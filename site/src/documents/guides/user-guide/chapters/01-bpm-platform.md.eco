# Process Engine<a id="process-engine"></a>

## Process Engine Bootstrapping<a id="process-engine-bootstrapping"></a>

There are two basic modes of the Process Engine:

* *Shared Process Engine:* A process engine that is provided by the bpm platform and may be shared between multiple process applications.
* *Embedded Process Engine:* A process engine that runs embedded in the application and is only used by that particular application.

See <a href="https://app.camunda.com/confluence/display/foxUserGuide/Architecture+Overview">Architecture Overview</a> for more details on the differences on this.

In order to configure and create a Process Engine you have different options:

* *Container managed Process Engine:* The container of your choice (e.g. Tomcat, JBoss, Glassfish or WebSphere) completly manages the Process Engine for you. Configuration is done in a container specific way, see Container Integration for details.
* *Application managed Process Engine:*
 * Create Process Engine via Java API: You can startup a Process Engine (shared or embedded) completly by plain Java code, more details below.
 * Create Process Engine using XML configuration: You can use an XML configuration (Spring) to configure and startup your Engine, more details below.
 * Create Process Engine using Spring: Spring can manage your Process Engine for you, see <a href="#programming-model-spring">Engine Startup via Spring</a> for details.
            
### ProcessEngineConfiguration bean<a id="process-engine-configuration-bean"></a>

The camunda engine uses the <a href="http://docs.camunda.org/api-references/java/?org/camunda/bpm/engine/ProcessEngineConfiguration.html">ProcessEngineConfiguration bean</a> to configure and construct a standalone Process Engine. There are multiple subclasses available that can be used to define the processEngineConfiguration. These classes represent different environments, and set defaults accordingly. It's a best practice to select the class the matches (the most) your environment, to minimalise the number of properties needed to configure the engine. The following classes are currently available:

* org.camunda.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration: the process engine is used in a standalone way. The engine itself will take care of the transactions. By default, the database will only be checked when the engine boots (and an exception is thrown if there is no database schema or the schema version is incorrect).
* org.camunda.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration: this is a convenience class for unit testing purposes. The engine itself will take care of the transactions. An H2 in-memory database is used by default. The database will be created and dropped when the engine boots and shuts down. When using this, probably no additional configuration is needed (except when using for example the job executor or mail capabilities).
* org.camunda.bpm.engine.spring.SpringProcessEngineConfiguration: To be used when the process engine is used in a Spring environment. See the Spring integration section for more information.
* org.camunda.bpm.engine.impl.cfg.JtaProcessEngineConfiguration: To be used when the engine runs in standalone mode, with JTA transactions.

### Bootstrap a Process Engine using Java API<a id="bootstrap-a-process-engine-java-api"></a>

You can completly configure the engine programatically by creating the right ProcessEngineConfiguration object or use some pre-defined one:

    ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();
    ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration();

Now you can call the buildProcessEngine() operation to create a Process Engine:

    ProcessEngine processEngine = ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration()
      .setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_FALSE)
      .setJdbcUrl("jdbc:h2:mem:my-own-db;DB_CLOSE_DELAY=1000")
      .setJobExecutorActivate(true)
      .buildProcessEngine();

### Configure Process Engine via XML<a id="configure-process-engine-via-xml"></a>

The easiest way to configure your Process Engine is via through an XML file called activiti.cfg.xml. Using that you can simply do:

    ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine()

The activiti.cfg.xml must contain a bean that has the id 'processEngineConfiguration', select the best fitting ProcessEngineConfiguration class suiting your needs:

    <bean id="processEngineConfiguration" class="org.camunda.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration">

This will look for an activiti.cfg.xml file on the classpath and construct an engine based on the configuration in that file. The following snippet shows an example configuration:

    <beans xmlns="http://www.springframework.org/schema/beans" 
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           xsi:schemaLocation="http://www.springframework.org/schema/beans   http://www.springframework.org/schema/beans/spring-beans.xsd">

      <bean id="processEngineConfiguration" class="org.camunda.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration">
      
        <property name="jdbcUrl" value="jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000" />
        <property name="jdbcDriver" value="org.h2.Driver" />
        <property name="jdbcUsername" value="sa" />
        <property name="jdbcPassword" value="" />
        
        <property name="databaseSchemaUpdate" value="true" />
        
        <property name="jobExecutorActivate" value="false" />
        
        <property name="mailServerHost" value="mail.my-corp.com" /> 
        <property name="mailServerPort" value="5025" />    
      </bean>

    </beans>

Note that the configuration XML is in fact a Spring configuration. This does not mean that the camunda engine can only be used in a Spring environment! We are simply leveraging the parsing and dependency injection capabilities of Spring internally for building up the engine.

The ProcessEngineConfiguration object can also be created programmatically using the configuration file. It is also possible to use a different bean id:

    ProcessEngineConfiguration.createProcessEngineConfigurationFromResourceDefault();
    ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource);
    ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource, String beanName);
    ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream);
    ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(InputStream inputStream, String beanName);

It is also possible not to use a configuration file, and create a configuration based on defaults (see the different supported classes for more information).

    ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();
    ProcessEngineConfiguration.createStandaloneInMemProcessEngineConfiguration();

All these `ProcessEngineConfiguration.createXXX()` methods return a ProcessEngineConfiguration that can further be tweaked if needed. After calling the `buildProcessEngine()` operation, a ProcessEngine is created as explained above.

## Process Engine API<a id="process-engine-api"></a>

### Services API<a id="services-api"></a>

The Java API is the most common way of interacting with the engine. The central starting point is the ProcessEngine, which can be created in several ways as described in the configuration section. From the ProcessEngine, you can obtain the various services that contain the workflow/BPM methods. ProcessEngine and the services objects are thread safe. So you can keep a reference to 1 of those for a whole server. 
    
<img src="<%= @docUrl('assets/img/implementation-java/api.services.png') %>">

    ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();

    RuntimeService runtimeService = processEngine.getRuntimeService();
    RepositoryService repositoryService = processEngine.getRepositoryService();
    TaskService taskService = processEngine.getTaskService();
    ManagementService managementService = processEngine.getManagementService();
    IdentityService identityService = processEngine.getIdentityService();
    HistoryService historyService = processEngine.getHistoryService();
    FormService formService = processEngine.getFormService();
  

`ProcessEngines.getDefaultProcessEngine()` will initialize and build a process engine the first time it is called and afterwards always return the same process engine. Proper creation and closing of all process engines can be done with `ProcessEngines.init()` and `ProcessEngines.destroy()`.

The ProcessEngines class will scan for all activiti.cfg.xml and activiti-context.xml files. For all `activiti.cfg.xml` files, the process engine will be built in the typical way: `ProcessEngineConfiguration.createProcessEngineConfigurationFromInputStream(inputStream).buildProcessEngine()`. For all `activiti-context.xml` files, the process engine will be built in the Spring way: First the Spring application context is created and then the process engine is obtained from that application context.

All services are stateless. This means that you can easily run camunda BPM on multiple nodes in a cluster, each going to the same database, without having to worry about which machine actually executed previous calls. Any call to any service is idempotent regardless of where it is executed.

The **RepositoryService** is probably the first service needed when working with the camunda engine. This service offers operations for managing and manipulating deployments and process definitions. Without going into much detail here, a process definition is a Java counterpart of BPMN 2.0 process. It is a representation of the structure and behaviour of each of the steps of a process. A deployment is the unit of packaging within the engine. A deployment can contain multiple BPMN 2.0 xml files and any other resource. The choice of what is included in one deployment is up to the developer. It can range from a single process BPMN 2.0 xml file to a whole package of processes and relevant resources (for example the deployment 'hr-processes' could contain everything related to hr processes). The RepositoryService allows to deploy such packages. Deploying a deployment means it is uploaded to the engine, where all processes are inspected and parsed before being stored in the database. From that point on, the deployment is known to the system and any process included in the deployment can now be started.

Furthermore, this service allows to

* query on deployments and process definitions known to the engine.
* Suspend and activate process definitions. Suspending means no further operations can be done on them, while activation is the opposite operation.
* Retrieve various resources such as files contained within the deployment or process diagrams that were auto generated by the engine.

Wile the RepositoryService is rather about static information (ie. data that doesn't change, or at least not a lot), the **RuntimeService** is quite the opposite. It deals with starting new process instances of process definitions. As said above, a process definition defines the structure and behaviour of the different steps in a process. A process instance is one execution of such a process definition. For each process definition there typically are many instances running at the same time. The RuntimeService also is the service which is used to retrieve and store process variables. This is data which is specific to the given process instance and can be used by various constructs in the process (eg. an exclusive gateway often uses process variables to determine which path is chosen to continue the process). The Runtimeservice also allows to query on process instances and executions. Executions are a representation of the 'token' concept of BPMN 2.0. Basically an execution is a pointer pointing to where the process instance currently is. Lastly, the RuntimeService is used whenever a process instance is waiting for an external trigger and the process needs to be continued. A process instance can have various wait states and this service contains various operations to 'signal' the instance that the external trigger is received and the process instance can be continued.

Tasks that need to be performed by actual human users of the system are core to the process engine. Everything around tasks is grouped in the **TaskService**, such as

* Querying tasks assigned to users or groups.
* Creating new standalone tasks. These are tasks that are not related to a process instances.
* Manipulating to which user a task is assigned or which users are in some way involved with the task.
* Claiming and completing a task. Claiming means that someone decided to be the assigee for the task, meaning that this user will complete the task. Completing means 'doing the work of the tasks'. Typically this is filling in a form of sorts.

The **IdentityService** is pretty simple. It allows the management (creation, update, deletion, querying, ...) of groups and users. It is important to understand that the core engine actually doesn't do any checking on users at runtime. For example, a task could be assigned to any user, but the engine does not verify if that user is known to the system. This is because the engine can also used in conjunction with services such as ldap, active directory, etc.

The **FormService** is an optional service. Meaning that the camunda engine can perfectly be used without it, without sacrificing any functionality. This service introduces the concept of a start form and a task form. A start form is a form that is shown to the user before the process instance is started, while a task form is the form that is displayed when a user wants to complete a form. You can define these forms in the BPMN 2.0 process definition. This service exposes this data in an easy way to work with. But again, this is optional as forms don't need to be embedded in the process definition.

The **HistoryService** exposes all historical data gathered by the engine. When executing processes, a lot of data can be kept by the engine (this is configurable) such as process instance start times, who did which tasks, how long it took to complete the tasks, which path was followed in each process instance, etc. This service exposes mainly query capabilities to access this data.

The **ManagementService** is typically not needed when coding custom application. It allows to retrieve information about the database tables and table metadata. Furthermore, it exposes query capabilities and management operations for jobs. Jobs are used in the engine for various things such as timers, asynchronous continuations, delayed suspension/activation, etc. Later on, these topics will be discussed in more detail.

<div class="alert">
   <strong>Javadocs: </strong> 
  <p>For more detailed information on the service operations and the engine API, see the <a href="http://docs.camunda.org/api-references/java/">javadocs</a>.</p>
</div>

    
### Query API<a id="query-api"></a>

To query data from the engine is possible in multiple ways:

* Java Query API: Fluent Java API to query engine entities (like ProcessInstances, Tasks, ...).
* REST Query API: REST API to query engine entities (like ProcessInstances, Tasks, ...).
* Native Queries: Provide own SQL queries to retrieve engine entities (like ProcessInstances, Tasks, ...) if the Query API lacks possibilities you need (e.g. OR conditions).
* Custom Queries: Use completly custom queries and an own MyBatis mapping to retrieve own value objects or join engine with domain data.
* SQL Queries: Use database SQL queries for use cases like Reporting.

The recommended way is to use on of the Query APIs.

The Java Query API allows to program completely typesafe queries with a fluent API You can add various conditions to your queries (all of which are applied together as a logical AND) and precisely one ordering. The following code shows an example:

    List<Task> tasks = taskService.createTaskQuery()
      .taskAssignee("kermit")
      .processVariableValueEquals("orderId", "0815")
      .orderByDueDate().asc()
      .list();

You can find more information on this in the <a href="http://docs.camunda.org/api-references/java/">javadocs</a>.

#### REST Query API

The Java Query API is exposed as REST service as well, see [REST documentation](<%= @docUrl('api-references/rest/') %>) for details.

#### Native Queries
 
Sometimes you need more powerful queries, e.g. queries using an OR operator or restrictions you can not express using the Query API. For these cases, we introduced native queries, which allow you to write your own SQL queries. The return type is defined by the Query object you use and the data is mapped into the correct objects, e.g. Task, ProcessInstance, Execution, etc.... Since the query will be fired at the database you have to use table and column names as they are defined in the database; this requires some knowledge about the internal data structure and it is recommended to use native queries with care. The table names can be retrieved via the API to keep the dependency as small as possible.

    List<Task> tasks = taskService.createNativeTaskQuery()
      .sql("SELECT count(\*) FROM " + managementService.getTableName(Task.class) + " T WHERE T.NAME_ = #{taskName}")
      .parameter("taskName", "gonzoTask")
      .list();

    long count = taskService.createNativeTaskQuery()
      .sql("SELECT count(\*) FROM " + managementService.getTableName(Task.class) + " T1, "
             + managementService.getTableName(VariableInstanceEntity.class) + " V1 WHERE V1.TASK_ID_ = T1.ID_")
      .count();

#### Custom Queries

For performance reasons it might sometimes be desirable not to query the engine objects but some own value or DTO objects collecting data from different tables - maybe including your own domain classes.

See <a href="https://app.camunda.com/confluence/display/foxUserGuide/Performance+Tuning+with+custom+Queries">Performance Tuning with custom Queries</a>.

#### SQL Queries

The table layout is pretty straightforward - we concentrated on making it easy to understand. Hence it is OK to do SQL queries for e.g. reporting use cases. Just make sure that you do not mess up the engine data by updating the tables without exactly knowing what you are doing.

See <a href="https://app.camunda.com/confluence/display/foxUserGuide/Reports+with+BIRT">Reports with BIRT</a> as example use case.

## Process Engine Concepts<a id="process-engine/concepts"></a>

This section explains some core process engine concepts that are used in both the process engine API and the internal process engine implementation. Understanding these fundamentals makes it easyier to use the process engine API. 

### Process Definitions<a id="process-engine/concepts/process-definitions"></a>

A process definition defines the structure of a process. You could say that the process definition *is* the process. camunda BPM uses [BPMN 2.0](http://www.camunda.org/design/tutorial.html) as its primary modeling language for modeling process definitions. 

<div class="alert alert-info">
  <strong>BPMN 2.0 Reference </strong> 
  <p>camunda BPM comes with two BPMN 2.0 References:
  <ul>
    <li>The <a href="http://www.camunda.org/design/reference.html#!/reference">BPMN 2.0 Modeling Reference</a> introduces the fundamentals of BPMN 2.0 and helps you to get started modeling processes. (Make sure to read the <a href="http://www.camunda.org/design/tutorial.html">Tutorial</a> as well.)</li>
    <li>The <a href="/api-references/bpmn20/">BPMN 2.0 Implementation Reference</a> covers the implementation of the individual BPMN 2.0 constructs in camunda BPM. You should consult this reference if you want to implement and execute BPMN processes.</li>
  </p>
</div>  

In camunda BPM you can deploy processes to the process engine in BPMN 2.0 XML format. The XML files are parsed and transformed into a process definition graph structure. This graph structure is executed by the process engine. 

#### Querying for Process Definitions<a id="process-engine/concepts/process-definitions/query"></a> 

You can query for all deployed process definitions using the Java API and the `ProcessDefinitionQuery` made available through the `RepositoryService`. Example:

    List<ProcessDefinition> processDefinitions = repositoryService.createProcessDefinitionQuery()
        .processDefinitionKey("invoice")
        .orderByProcessDefinitionVersion()
        .asc()
        .list();

The above query returns all deployed process definitions for the key `invoice` ordered by their `version` property. 

You can also [query for process definitions using the REST API](/api-references/rest/#!/process-definition/get-query).

#### Keys and Versions <a id="process-engine/concepts/process-definitions/key-version"></a> 

The *key* of a process definition (`invoice` in the example above) is the logical identifier of the process. It is used throughout the API, most prominently for starting process instances ([see section on process instances](#!/#process-engine/concepts/process-instances)). The key of a process definition is defined using the `id` property of the corresponding `<process ... >` element in the BPMN 2.0 XML file:

    <process id="invoice" name="invoice receipt" isExecutable="true">
      ...
    </process>

If you deploy multiple processes with the same key, they are treated as individual versions of the same process definition by the process engine. 

#### Suspending Process Definitions ####

Suspending a process definition disables it temporarily in that it cannot be instantiated while it is suspended. The `RuntimeService` Java API can be used to suspend a process definition. Similarly, you can activate a process definition to undo this effect.

### Process Instances<a id="process-engine/concepts/process-instances"></a>

A process instance is an individual execution of a process definition. The relation of the process instance to the process definition is the same as the relation between *Object* and *Class* in Object Oriented Programming (the process instance playing the role of the object and the process definition playing the role of the class in this analogy).

The process engine is responsible for creating process instances and managing their state. If you start a process instance which contains a wait state, for example a [user task](/api-references/bpmn20/#!/tasks/user-task), the process engine must make sure that the state of the process instance is captured and stored inside a database until the wait state is left (the user task is completed). 

#### Starting a Process Instance<a id="process-engine/concepts/process-instances/start"></a> 

The simplest way to start a process instance is by using the `startProcessInstanceByKey(...)` method offered by the RuntimeService:

    ProcessInstance instance = runtimeService.startProcessInstanceByKey("invoce");

You may optionally pass in a couple of variables:

    Map<String, Object> variables = new HashMap<String,Object>();
    variables.put("creditor", "Nice Pizza Inc.");
    ProcessInstance instance = runtimeService.startProcessInstanceByKey("invoce", variables);

Process variables are available to all tasks in a process instance and are automatically persisted to the database in case the process instance reaches a wait state.

It is also possible to [start a process instance using the REST API](/api-references/rest/#!/process-definition/post-start-process-instance).

#### Querying for Process Instances<a id="process-engine/concepts/process-instances/query"></a> 

You can query for all currently running process instances using the `ProcessInstanceQuery` offered by the `RuntimeService`: 

    runtimeService.createProcessInstanceQuery()
        .processDefinitionKey("invoice")
        .variableValueEquals("creditor", "Nice Pizza Inc.")
        .list();

The above query would select all process instances for the `invoice` process where the `creditor` is `Nice Pizza Inc.`. 

You can also [query for process instances using the REST API](/api-references/rest/#!/process-instance/get-query).

#### Interacting with a Process Instance<a id="process-engine/concepts/process-instances/interact"></a> 

Once you have performed a query for a particular process instance (or a list of process instances), you may want to interact with it. There are multiple possibilities to interact with a process instance, most prominently: 

  * Triggering it (make it continue execution):
      * Through a [Message Event](/api-references/bpmn20/#!/events/message-events)
      * Through a [Signal Event](/api-references/bpmn20/#!/events/signal-events)
  * Canceling it:
      * Using the `RuntimeService.deleteProcessInstance(...)` method.

If your process uses User Task, you can also interact with the process instance using the TaskService API.

#### Suspending Process Instances ####

Suspending a process instance is helpful, if you want ensure that it is not executed any further. For example, if process variables are in an undesired state, you can suspend the instance and change the variables *safely*.

In detail, suspension means to disallow all actions that change *token* state (i.e. the activities that are currently executed) of the instance. For example, it is not possible to signal an event or complete a user task for a suspended process instance, as these actions will continue the process instance execution subsequently. Nevertheless, actions like setting or removing variables are still allowed, as they do not change token state.

Also, when suspending a process instance, all tasks belonging to it will be suspended. Therefore, it will no longer be possible to invoke actions that have effects on the task's *lifecycle* (i.e. user assignment, task delegation, task completion, ...). However, any actions not touching the lifecycle like setting variables or adding comments will still be allowed.

A process instance can be suspended by using the `suspendProcessInstanceById(...)` method of the `RuntimeService`. Similarly it can be reactivated again.

If you would like to suspend all process instances of a given process definition, you can use the method `suspendProcessDefinitionById(...)` of the`RepositoryService` and specify the `suspendProcessInstances` option.

### Executions<a id="process-engine/concepts/executions"></a>

If your process instance contains multiple execution paths (like for instance after a [parallel gateway](/api-references/bpmn20/#!/gateways/parallel-gateway)), you must be able to differentiate the currently active paths inside the process instance. In the following example, two user tasks *receive payment* and *ship order* can be active at the same time.

<img src="assets/img/parallel-gw.png"></img>

Internally the process engine creates two concurrent executions inside the process instance, one for each concurrent path of execution. Executions are also created for scopes, for example if the process engine reaches a [Embedded Sub Process](/api-references/bpmn20/#!/subprocesses/embedded-subprocess) or in case of [Multi Instance](/api-references/bpmn20/#!/tasks/task-markers).

Executions are hierarchical and all executions inside a process instance span a tree, the process instance being the root-node in the tree. Note: the process instance itself is an execution.

#### Local Variables

Executions can have local variables. Local variables are only visible to the execution itself and its children but not to siblings of parents in the execution tree. Local variables are usually used if a part of the process works on some local data object or if an execution works on one item of a collection in case of multi instance. 

In order to set a local variable on an execution, use the `setVariableLocal` method provided by the runtime service. 

    runtimeService.setVariableLocal(name, value);

#### Querying for executions

You can query for executions using the `ExecutionQuery` offered by the `RuntimeService`: 

    runtimeService.createProcessInstanceQuery()
        .processInstanceId(someId)
        .list();

The above query returns all executions for a given process instance.

You can also [query for executions using the REST API](/api-references/rest/#!/execution/get-query).

### Activity Instances<a id="process-engine/concepts/activity-instances"></a>

The activity instance concept is similar to the execution concept but takes a different perspective. While an execution can be imagined as a *token* moving through the process, an activity instance represents an individual instance of an activity (task, subprocess, ...). The concept of the activity instance is thus more *state-oriented*.

Activity instances also span a tree, following the scope structure provided by BPMN 2.0. Activities that are "on the same level of subprocess" (ie. part of the same scope, contained in the same subprocess) will have their activity instances at the same level in the tree

Examples:

  * Process with two parallel user tasks after parallel Gateway: in the activity instance tree you will see two activity instances below the root instance, one for each user task. 
  * Process with two parallel Multi Instance user tasks after parallel Gateway: in the activity instance tree, all instances of both user tasks will be listed below the root activity instance. Reason: all activity instances are at the same level of subprocess. 
  * Usertask inside embedded subprocess: the activity instance three will have 3 levels: the root instance representing the process instance itself, below it an activity instance representing the instance of the embedded subprocess, and below this one, the activity instance representing the usertask. 

#### Retrieving an Activity Instance 

Currently activity instances can only be retrieved for a process instance: 

    ActivityInstance rootActivityInstance = runtimeService.getActivityInstance(processInstance.getProcessInstanceId());

You can <a href="/api-references/rest/#!/process-instance/get-activity-instances">retrieve the activity instance tree using the REST API</a> as well.

#### Identity & Uniqueness:
Each activity instance is assigned a unique Id. The id is persistent, if you invoke this method multiple times, the same activity instance ids will be returned for the same activity instances. (However, there might be different executions assigned, see below)

#### Relation to Executions
The Execution concept in the process engine is not completely aligned with the activity instance concept because the execution tree is in general not aligned with the activity / scope concept in BPMN. In general, there is a n-1 relationship between Executions and ActivityInstances, ie. at a given point in time, an activity instance can be linked to multiple executions. In addition, it is not guaranteed that the same execution that started a given activity instance will also end it. The process engine performs several internal optimizations concerning the compacting of the execution tree which might lead to executions being reordered and pruned. This can lead to situations where a given execution starts an activity instance but another execution ends it. Another special case is the process instance: if the process instance is executing a non-scope activity (for example a user task) below the process definition scope, it will be referenced by both the root activity instance and the user task activity instance. 

Note: If you need to interpret the state of a process instance in terms of a BPMN process model, it is usually easier to use the activity instance tree as opposed to the execution tree.

## Database configuration<a id="database-configuration"></a>

There are two ways to configure the database that the camunda engine will use. The first option is to define the JDBC properties of the database:

* `jdbcUrl`: JDBC URL of the database.
* `jdbcDriver`: implementation of the driver for the specific database type.
* `jdbcUsername`: username to connect to the database.
* `jdbcPassword`: password to connect to the database.

Note that internally the engine uses <a href="http://www.mybatis.org/">Apache MyBatis</a> for persistence. 

The data source that is constructed based on the provided JDBC properties will have the default MyBatis connection pool settings. The following attributes can optionally be set to tweak that connection pool (taken from the MyBatis documentation):

* `jdbcMaxActiveConnections`: The number of active connections that the connection pool at maximum at any time can contain. Default is 10.
* `jdbcMaxIdleConnections`: The number of idle connections that the connection pool at maximum at any time can contain.
* `jdbcMaxCheckoutTime`: The amount of time in milliseconds a connection can be 'checked out' from the connection pool before it is forcefully returned. Default is 20000 (20 seconds).
* `jdbcMaxWaitTime`: This is a low level setting that gives the pool a chance to print a log status and re-attempt the acquisition of a connection in the case that it's taking unusually long (to avoid failing silently forever if the pool is misconfigured) Default is 20000 (20 seconds).

Example database configuration:

    <property name="jdbcUrl" value="jdbc:h2:mem:camunda;DB_CLOSE_DELAY=1000" />
    <property name="jdbcDriver" value="org.h2.Driver" />
    <property name="jdbcUsername" value="sa" />
    <property name="jdbcPassword" value="" />
     

Alternatively, a `javax.sql.DataSource` implementation can be used (e.g. DBCP from Apache Commons):
    
    <bean id="dataSource" class="org.apache.commons.dbcp.BasicDataSource" >
      <property name="driverClassName" value="com.mysql.jdbc.Driver" />
      <property name="url" value="jdbc:mysql://localhost:3306/camunda" />
      <property name="username" value="camunda" />
      <property name="password" value="camunda" />
      <property name="defaultAutoCommit" value="false" />
    </bean>      

    <bean id="processEngineConfiguration" class="org.camunda.bpm.engine.impl.cfg.StandaloneProcessEngineConfiguration">
      
        <property name="dataSource" ref="dataSource" />
        ...


Note that camunda does not ship with a library that allows to define such a data source. So you have to make sure that the libraries (e.g. from DBCP) are on your classpath.

The following properties can be set, regardless of whether you are using the JDBC or data source approach:

* `databaseType`: it's normally not necessary to specify this property as it is automatically analyzed from the database connection meta data. Should only be specified in case automatic detection fails. Possible values: {h2, mysql, oracle, postgres, mssql, db2}. This property is required when not using the default H2 database. This setting will determine which create/drop scripts and queries will be used. See the 'supported databases' section for an overview of which types are supported.</li>
* `databaseSchemaUpdate`: allows to set the strategy to handle the database schema on process engine boot and shutdown.
  * `false` (default): Checks the version of the DB schema against the library when the process engine is being created and throws an exception if the versions don't match.
  * `true`: Upon building the process engine, a check is performed and an update of the schema is performed if it is necessary. If the schema doesn't exist, it is created.
  * `create-drop`: Creates the schema when the process engine is being created and drops the schema when the process engine is being closed. 

<div class="alert">
  <strong>Supported Databases: </strong> 
  <p>For information on supported databases please refer to <a href="https://app.camunda.com/confluence/display/foxUserGuide/Supported+environments">Supported Environments</a>.</p>
</div>  

Here are some sample JDBC urls:

* h2: jdbc:h2:tcp://localhost/camunda
* mysql: jdbc:mysql://localhost:3306/camunda?autoReconnect=true
* oracle: jdbc:oracle:thin:@localhost:1521:xe
* postgres: jdbc:postgresql://localhost:5432/camunda
* db2: jdbc:db2://localhost:50000/camunda
* mssql: jdbc:sqlserver://localhost:1433/camunda

For more information on the database setup please refer to <a href="https://app.camunda.com/confluence/display/foxUserGuide/Database+Setup">Database Setup</a>

## Database table names explained<a id="database-table-names"></a>

The table names all start with ACT. The second part is a two-character identification of the use case of the table. This use case will also roughly match the service API.

* ACT_RE_*: 'RE' stands for repository. Tables with this prefix contain 'static' information such as process definitions and process resources (images, rules, etc.).
* ACT_RU_*: 'RU' stands for runtime. These are the runtime tables, that contain the runtime data of process instances, user tasks, variables, jobs, etc. The engine only stores the runtime data during process instance execution, and removes the records when a process instance ends. This keeps the runtime tables small and fast.
* ACT_ID_*: 'ID' stands for identity. These tables contain identity information, such as users, groups, etc.
* ACT_HI_*: 'HI' stands for history. These are the tables that contain historic data, such as past process instances, variables, tasks, etc.
* ACT_GE_*: general data, which is used in various use cases.

## History configuration<a id="history-configuration"></a>

Customizing the configuration of <a href="https://app.camunda.com/confluence/display/foxUserGuide/History">history</a> is optional. This allows you to tweak settings that influence the history capabilities of the engine. 

    <property name="history" value="audit" />

## Process Definition Cache<a id="process-definition-cache"></a>

All process definition are cached (after they're parsed) to avoid hitting the database every time a process definition is needed and because process definition data doesn't change.

## Transactions in Processes<a id="transactions"></a>

A process engine is a set of objects which are initialized and wait for threads that want to perform work in a particular process instance. It is essentially a passive component triggered only by these threads. For instance, if you have a web application allowing users to start a new process instance and a user clicks on the corresponding button, some thread from the application server's http-thread-pool will invoke the API method `runtimeService.startProcessInstanceByKey(...)`, thus *entering* the process engine and starting a new process instance. 

On any such *external* trigger (i.e. start a process, complete a task, signal an execution), the engine runtime is going to advance in the process until it reaches wait states on each active path of execution. More concretely speaking it performs a depth-first traversal through the process graph and returns if it has reached wait states on every branch of execution. A wait state is a task which is performed *later*, which means that the engine persists the current execution and waits to be triggered again. For example in case of a user task, the external trigger on task completion causes the runtime to execute the next bit of the process until wait states are reached again (or the instance ends). In contrast to user tasks, a timer event is not triggered externally. Instead it is continued by an *internal* trigger. That is why the engine also needs an active component, the [job executor](#!/#job-executor), which is able to fetch registered jobs and process them asynchronously.

### Transaction Boundaries<a id="transaction-boundaries"></a>

The transition from one such stable state to another stable state is always part of one transaction, meaning that it succeeds as a whole or is rolled back on any kind of exception occuring during its execution. This is illustrated in the following example:

<img src="<%= @docUrl('guides/user-guide/assets/img/transactions-1.png') %>">

We see a segment of a BPMN process with a user task, a service task and a timer event. The timer event marks the next wait state. Completing the user task and validating the address is therefore part of the same unit of work, so it should succeed or fail atomically. That means that if the service task throws an exception we want to rollback the current transaction, such that the execution tracks back to the user task and the user task is still present in the database. This is also the default behavior of the process engine.

In **1**, an application or client thread completes the task. In that same thread the engine runtime is now executing the service task and advances until it reaches the wait state at the timer event (**2**). Then it returns the control to the caller (**3**) potentially committing the transaction (if it was started by the engine). 

In some cases this behavior is not desired. Sometimes we need custom control over transaction boundaries in a process, in order to be able to scope logical units of work. Consider the following process fragment: 

<img src="<%= @docUrl('guides/user-guide/assets/img/transactions-2.png') %>">

This time we are completing the user task, generating an invoice and then send that invoice to the customer. This time the generation of the invoice is not part of the same unit of work so we do not want to rollback the completion of the usertask if generating an invoice fails. So what we want the engine to do is complete the user task (**1**), commit the transaction and return the control to the calling application (**2**). 

Then we want to generate the invoice asynchronously, in a background thread. A pool of background threads is manged by the [job executor](#!/#job-executor). It periodically checks the database for asynchronous *jobs*, i.e. units of work in the process runtime. 

So behind the scenes, when we reach the *generate invoice* task, we are persisting a job in the database, queueing it for later execution. This job is then picked up by the job executor and executed (**3**). We are also giving the local job executor a little hint that there is a new job, to improve performance. In order to use this feature, we can use the `camundabpm:async="true"` extension in the BPMN 2.0 XML. So for example, the service task would look like this:

    <serviceTask id="service1" name="Generate Invoice" camundabpm:class="my.custom.Delegate" camundabpm:async="true" /> 
        
`camundabpm:async` can be specified on the following bpmn task types: `task`, `serviceTask`, `scriptTask`, `businessRuleTask`, `sendTask`, `receiveTask`, `userTask`, `subProcess` and `callActivity`. On a user task, receive task or other wait states, the additional async continuation allows us to execute the start execution listeners in a separate thread/transaction. 

## The Job Executor<a id="job-executor"></a>

A job is an explicit representation of a task to trigger process execution. A job is created whenever a wait state is reached during process execution that has to be triggered internally. This is the case when a timer event or a task marked for asynchronous execution (see [transaction boundaries](#!/#transaction-boundaries)) is approached. The job executor has two responsibilities: job acquisition and job execution. The following diagram illustrates this:

<img src="<%= @docUrl('guides/user-guide/assets/img/job-executor-basic-architecture.png') %>">

### Job Executor Activation<a id="job-executor-activation"></a>

By default, the JobExecutor is activated when the process engine boots. For unit testing scenarios it is cumbersome to work with this background component. Therefore the Java API offers to query for (`ManagementService.createJobQuery`) and execute jobs (`ManagementService.executeJob`) *by hand*, which allows to control job execution from within a unit test. To avoid interference with the job executor, it can be switched off.

Specify

    <property name="jobExecutorActivate" value="false" />

in the process engine configuration when you don't want the JobExecutor to be activated upon booting the process engine.

### Job Acquisition<a id="job-acquisition"></a>

Job acquisition is the process of retrieving jobs from the database that are to be executed next. Therefore jobs must be persisted to the database together with properties determining whether a job can be executed. For example, a job created for a timer event may not be executed before the defined time span has passed.

#### Persistency

Jobs are persisted to the database, in the ACT_RU_JOB table. This database table has the following columns (among others): 

	ID_ | REV_ | LOCK_EXP_TIME_ | LOCK_OWNER_ | RETRIES_ | DUEDATE_

Job acquisition is concerned with polling this database table and locking jobs.

#### Acquirable Jobs

A job is acquirable, i.e. a candidate for execution, if

* it is due, meaning that the value in the DUEDATE&#95; column is in the past
* it is not locked, meaning that the value in the LOCK&#95;EXP&#95;TIME&#95; column is in the past
* its retries have not elapsed, meaning that the value in the RETRIES&#95; column is greater than zero.

In addition, the process engine has a concept of suspending a process definition and a process instance. A job is only acquirable if neither the corresponding process instance nor the corresponding process definition are suspended. 

#### The two Phases of Job Acquisition

Job acquisition has two phases. In the first phase the job executor queries for a configurable amount of acquirable jobs. If at least one job can be found, it enters the second phase, locking the jobs. Locking is necessary in order to ensure that jobs are executed exactly once. In a clustered scenario, it is accustom to operate multiple job executor instances (one for each node) that all poll the same ACT&#95;RU&#95;JOB table. Locking a job ensures that it is only acquired by a single job executor instance. Locking a job means updating its values in the LOCK&#95;EXP&#95;TIME&#95; and LOCK&#95;OWNER_ columns. The LOCK&#95;EXP&#95;TIME&#95; column is updated with a timestamp signifying a date that lies in the future. The intuition behind this is that we want to lock the job until that date is reached. The LOCK&#95;OWNER&#95; column is updated with a value uniquely identifying the current job executor instance. In a clustered scenario this could be a node name uniquely identifying the current cluster node.

The situation where multiple job executor instances attempt to lock the same job concurrently is accounted for by using optimistic locking (see REV&#95; column).

After having locked a job, the job executor instance has effectively reserved a time slot for executing the job: once the date written to the LOCK&#95;EXP&#95;TIME&#95; column is reached it will be visible to job acquisition again. In order to execute the acquired jobs, they are passed to the acquired jobs queue. 

###Job Execution<a id="job-execution"></a>

#### Thread Pool

Acquired jobs are executed by a thread pool. The thread pool consumes jobs from the acquired jobs queue. The acquired jobs queue is an in-memory queue with a fixed capacity. When an executor starts executing a job, it is first removed from the queue.

In the scenario of an embedded process engine, the default implementation for this thread pool is a `java.util.concurrent.ThreadPoolExecutor`. However, this is not allowed in Java EE environments. There we hook into the application server capabilities of thread management. See the platform-specific information in the [Runtime Container Integration](#!/#runtime-container-integration) section on how this achieved.

#### Failed Jobs

Upon failure of job execution, e.g. if a service task invocation throws an exception, a job will be retried a number of times (by default 3). It is not immediately retried and added back to the acquisition queue, but the value of the RETRIES&#95; column is updated. The process engine thus performs bookkeeping for failed jobs. After updating the RETRIES&#95; column, the executor moves on to the next job. This means that the failed job will automatically be retried once the LOCK&#95;EXP&#95;TIME&#95; date is expired.

In real life it is useful to configure the retry strategy, i.e. the number of times a job is retried and when it is retried, so the LOCK&#95;EXP&#95;TIME&#95;. In the camunda engine, this can be configured as an extension element of a task in the BPMN 2.0 XML:
    
    <definitions ... xmlns:fox="http://www.camunda.com/fox">
      ...
      <serviceTask id="failingServiceTask" camundabpm:async="true" camundabpm:class="org.camunda.engine.test.cmd.FailingDelegate">
        <extensionElements>
         <fox:failedJobRetryTimeCycle>R5/PT5M</fox:failedJobRetryTimeCycle>
        </extensionElements>
      </serviceTask>
      ...
    </definitions>
	
The configuration follows the [ISO_8601 standard for repeating time intervals](http://en.wikipedia.org/wiki/ISO_8601#Repeating_intervals). In the example, `R5/PT5M` means that the maximum number of retries is 5 (`R5`) and the delay of retry is 5 minutes (`PT5M`).

Similarly, the following example defines three retries after 5 seconds each for a boundary timer event:

	<boundaryEvent id="BoundaryEvent_1" name="Boundary event" attachedToRef="Freigebenden_zuordnen_143">
		<extensionElements>
			<fox:failedJobRetryTimeCycle>R3/PT5S</fox:failedJobRetryTimeCycle>
		</extensionElements>
		<outgoing>SequenceFlow_3</outgoing>
		<timerEventDefinition id="sid-ac5dcb4b-58e5-4c0c-b30a-a7009623769d">
			<timeDuration xsi:type="tFormalExpression" id="sid-772d5012-17c2-4ae4-a044-252006933a1a">PT10S</timeDuration>
		</timerEventDefinition>
	</boundaryEvent>
	
Recap: a retry may be required, if there are any failures during the transaction which follows the timer.

### Concurrent Job Execution<a id="concurrent-job-execution"></a>

The Job Executor makes sure that **jobs from a single process instance are never executed concurrently**. Why is this? Consider the following process definition:

<img src="<%= @docUrl('guides/user-guide/assets/img/job-executor-exclusive-jobs.png') %>">

We have a parallel gateway followed by three service tasks which all perform an asynchronous continuation. As a result of this, three jobs are added to the database. Once such a job is present in the database it can be processed by the job executor. It acquires the jobs and delegates them to a thread pool of worker threads which actually process the jobs. This means that using an asynchronous continuation, you can distribute the work to this thread pool (and in a clustered scenario even across multiple thread pools in the cluster).

This is usually a good thing. However it also bears an inherent problem: consistency. Consider the parallel join after the service tasks. When the execution of a service task is completed, we arrive at the parallel join and need to decide whether to wait for the other executions or whether we can move forward. That means, for each branch arriving at the parallel join, we need to take a decision whether we can continue or whether we need to wait for one or more other executions from the other branches.

This requires synchronization between the branches of execution. The engine addresses this problem with optimistic locking. Whenever we take a decision based on data that might not be current (because another transaction might modify it before we commit), we make sure to increment the revision of the same database row in both transactions. This way, whichever transaction commits first wins and the other ones fail with an optimistic locking exception. This solves the problem in the case of the process discussed above: if multiple executions arrive at the parallel join concurrently, they all assume that they have to wait, increment the revision of their parent execution (the process instance) and then try to commit. Whichever execution is first will be able to commit and the other ones will fail with an optimistic locking exception. Since the executions are triggered by a job, the job executor will retry to perform the same job after waiting for a certain amount of time and hopefully this time pass the synchronizing gateway.

However, while this is a perfectly fine solution from the point of view of persistence and consistency, this might not always be desirable behavior at a higher level, especially if the execution has non-transactional side effects, which will not be rolled back by the failing transaction. For instance, if the *book concert tickets* service does not share the same transaction as the process engine, we might book multiple tickets if we retry the job. That is why jobs of the same process instance are processed *exclusively* by default.

#### Exclusive Jobs

An exclusive job cannot be performed at the same time as another exclusive job from the same process instance. Consider the process shown in the section above: if the jobs correpsonding to the service tasks are treated as exclusive, the job executor will make sure that they are not executed concurrently. Instead, it will ensure that whenever it acquires an exclusive job from a certain process instance, it also acquires all other exclusive jobs from the same process instance and delegates them to the same worker thread. This enforces sequential execution of the jobs.

**Exclusive Jobs are the default configuration**. All asynchronous continuations and timer events are thus exclusive by default. In addition, if you want a job to be non-exclusive, you can configure it as such using `camundabpm:exclusive="false"`. For example, the following service task would be asynchronous but non-exclusive.

	<serviceTask id="service" camundabpm:expression="${myService.performBooking(hotel, dates)}" camundabpm:async="true" camundabpm:exclusive="false" />
	
Is this a good solution? We had some people asking whether it was. Their concern was that it would prevent you from *doing things in parallel* and would thus be a performance problem. Again, two things have to be taken into consideration:

* It can be turned off if you are an expert and know what you are doing (and have understood this section). Other than that, it is more intuitive for most users if things like asynchronous continuations and timers just work.
* It is actually not a performance issue. Performance is an issue under heavy load. Heavy load means that all worker threads of the job executor are busy all the time. With exclusive jobs, the engine will simply distribute the load differently. Exclusive jobs means that jobs from a single process instance are performed by the same thread sequentially. But consider: you have more than one single process instance. And jobs from other process instances are delegated to other threads and executed concurrently. This means that with exclusive jobs the engine will not execute jobs from the same process instance concurrently but it will still execute multiple instances concurrently. From an overall throughput perspective this is desirable in most scenarios as it usually leads to individual instances being done more quickly.
  
### The Job Executor and Multiple Process Engines<a id="job-executor-multiple-engines"></a>

In the case of a single, application-embedded process engine, the job executor setup is the following:

<img src="<%= @docUrl('guides/user-guide/assets/img/job-executor-single-engine.png') %>">

There exists a single job table that the engine adds jobs to and the acquisition consumes from. Creating a second embedded engine would therefore create another acquisition thread and execution thread-pool.

In larger deployments however, this quickly leads to a poorly manageable situation. When running camunda BPM on Tomcat or an application server, the platform allows to declare multiple process engines shared by multiple process applications. With respect to job execution, one job acquisition may serve multiple job tables (and thus process engines) and a single thread-pool for execution may be used.

<img src="<%= @docUrl('guides/user-guide/assets/img/job-executor-multiple-engines.png') %>">

**This setup enables centralized monitoring of job acquisition and execution**.
See the platform-specific information in the [Runtime Container Integration](#!/#runtime-container-integration) section on how the thread pooling is implemented on the different platforms.

Different job acquisitions can also be configured differently, e.g. to meet business requirements like SLAs. For example, the acquisition's timeout when no more executable jobs are present can be configured differently per acquisition.

To which job acquisition a process engine is assigned can be specified in the declaration of the engine, so either in the `processes.xml` deployment descriptor of a process application or in the camunda BPM platform descriptor. The following is an example configuration that declares a new engine and assigns it to the job acquisition named `default`, which is created when the platform is bootstrapped.

    <process-engine name="newEngine">
      <job-acquisition>default</job-acquisition>
      ...
    </process-engine> 

Job acquisitions have to be declared in the BPM platform's deployment descriptor, see [the container-specific configuration options](#!/#configuration-and-extensions).

### Cluster Setups<a id="cluster-setups"></a>

When running the camunda platform in a cluster, there is a distinction between *homogeneous* and *heterogeneous* setups. We define a cluster as a set of network nodes that all run the camunda BPM platform against the same database (at least for one engine on each node). In the *homogeneous* case, the same process applications (and thus custom classes like JavaDelegates) are deployed to all of the nodes, as depicted below.

<img src="<%= @docUrl('guides/user-guide/assets/img/homogeneous-cluster.png') %>">

In the *heterogeneous* case, this is not given, meaning that some process applications are deployed to only part of the nodes.

<img src="<%= @docUrl('guides/user-guide/assets/img/heterogeneous-cluster.png') %>">

#### Job Execution in Heterogeneous Clusters

A heterogeneous cluster setup as described above poses additional challenges to the job executor. Both platforms declare the same engine, i.e. they run against the same database. This means that jobs will be inserted into the same table. However, in the default configuration the job acquisition thread of node 1 will lock any executable jobs of that table and submit them to the local job execution pool. This means, jobs created in the context of process application B (so on node 2), may be executed on node 1 and vice versa. As the job execution may involve classes that are part of B's deployment, you are likely going to see a `ClassNotFoundExeception` or any of the likes.

To prevent the job acquisition on node 1 from picking jobs that *belong* to node 2, the process engine can be configured as *deployment aware*, by the setting following property in the process engine configuration:

    <process-engine name="default">
      ...
      <properties>
        <property name="jobExecutorDeploymentAware">true</property>
        ...
      </properties>
    </process-engine>

Now, the job acquisition thread on node 1 will only pick up jobs that belong to deployments made on that node, which solves the problem. Digging a little deeper, the acquisition will only pick up those jobs that belong to deployments that were *registered* with the engines it serves. Every deployment gets automatically registered. Additionally, one can explicitly register and unregister single deployments with an engine by using the `ManagementService` methods `registerDeploymentForJobExecutor(deploymentId)` and `unregisterDeploymentForJobExecutor(deploymentId)`. It also offers a method `getRegisteredDeployments()` to inspect the currently registered deployments.

As this is configurable on engine level, you can also work in a *mixed* setup, when some deployments are shared between all nodes and some are not. You can assign the globally shared process applications to an engine that is not deployment aware and the others to a deployment aware engine, probably both running against the same database. This way, jobs created in the context of the shared process applications will get executed on any cluster node, while the others only get executed on their respective nodes.


## Logging<a id="logging"></a>

We use <a href="http://docs.oracle.com/javase/6/docs/api/java/util/logging/package-summary.html">Java Logging</a> to avoid any third party logging requirements. 


## Incidents<a id="incidents"></a>

Incidents are notable events that happen in the process engine. Such incidents usually indicate some kind of problem related to process execution. Examples of such incidents may be a failed job with elapsed retries (retries = 0), indicating that an execution is stuck and manual administrative action is necessary for repairing the process instance. Or the fact that a process instance has entered an error state which could be modelled as a BPMN Error Boundary event or a User Task explicitly marked as "error state". If such incidents arise, the process engine fires an internal event which can be handled by a configurable incident handler. 

In the default configuration, the process engine writes incidents to the process engine database. You may then query the database for different types and kinds of incidents using the `IncidentQuery` exposed by the `RuntimeServie`:

    runtimeService.createIncidentQuery()
      .processDefinitionId("someDefinition")
      .list();

Incidents are stored in the AC_RU_INCIDENT database table. 

If you want to customize the incident handling behavior, it is possible to replace the default incident handlers in the process engine configuration and provide custom implementations (see below).

### Incident Types<a id="incident-types"></a>

There are different types of incidents. Currently the process engine supports the following incidents:

  * **Failed Job**: this incident is raised when automatic retries for a Job (Timer or Asynchronous continuation) have elapsed. The incident indicates that the corresponding execution is stuck and will not continue automatically. Adminitrative action is necessary.
  The incident is resolved, when the job is executed manually or when the retries for the corresponding job are reset to a value > 0.

### (De-)Activating Incidents<a id="de-activating-incidents"></a>

The process engine allows you to configure on an incident type basis whether certain incidents should be raised or not. 

The following properties are available in the `org.camunda.bpm.engine.ProcessEngineConfiguration` class:

  * `createIncidentOnFailedJobEnabled`: indicates whether Failed Job incidents should be raised.

### Implementing custom Incident Handlers<a id="implementing-custom-incident-handlers"></a>

Incident Handlers are responsible for handling incidents of a certain type (see Incident Types below). 

An Incident Handler implements the following interface: 

    public interface IncidentHandler {
      
      public String getIncidentHandlerType();
      
      public void handleIncident(String processDefinitionId, String activityId, String executionId, String configuration);
      
      public void resolveIncident(String processDefinitionId, String activityId, String executionId, String configuration);

    }

The `handleIncident` method is called when a new incident is created. The `resolveIncident` method is called when an incident is resolved. If you want to provide a custom incident handler implementation you can replace one or multiple incident handlers using the following method:

    org.camunda.bpm.engine.impl.cfg.ProcessEngineConfigurationImpl.setCustomIncidentHandlers(List<IncidentHandler>)

An example of a custom inciddent handler could be a handler which, in addtion to the default behavior also sends an email to an administrator.


# Process Applications<a id="process-applications"></a>

A Process Application is an ordinary Java Application that uses the camunda process engine for BPM and Worklow functionality. Most such applications will start their own process engine (or use a process engine provided by the runtime container), deploy some BPMN 2.0 process definitions and interact with process instances derived from these process definitions. Since most process applications perform very similar bootstrapping, deployment and runtime tasks, we generalized this functionaly into a Java Class which is named - *Surprise!* - `ProcessApplication`. The concept is similar to the `javax.ws.rs.core.Application` class in JAX-RS: adding the process application class allows you to bootrap and configure the provided services.

Adding a `ProcessApplication` class to your Java Application provides your applications with the following services:
 
  * **Bootrapping** embedded process engine(s) or looking up container managed process engine(s). You can define multiple process engines in a file named `processes.xml` which is added to your application. The ProcessApplication class makes sure this file is picked up and the defined process engines are started and stopped as the application is deployed / undeployed. 
  * **Automatic deployment** of classpath BPMN 2.0 resources. You can define multiple deployments (process archives) in the `processes.xml` file. The process application class makes sure the deployments are performed upon deployment of your application. Scanning your application for process definition resource files (engine in *.bpmn20.xml or *.bpmn) is supported as well.
  * **Resolution of application-local Java Delegate Implementations** and Beans in case of a multi-application deployment. The process application class allows your java application to expose your local Java Delegate implementations or Spring / CDI beans to a shared, container managed process engine. This way you can start a single process engine that dispatches to multiple process applications that can be (re-)deployed independently.

Transforming an existing Java Application into a Process Application is easy and non-intrusive. You simply have to add:

* A Process Application class: The Process Application class constitutes the interface between your application and the process engine. There are different base classes you can extent to reflect different environments (e.g. Servlet vs. EJB Container).
* A processes.xml file to META-INF: The deployment descriptor file allows  to provide a declarative configuration of the deployment(s) this process application makes to the process engine. It can be empty and serve as simple marker file - but it must be present.

<div class="alert">
  <p>
    <strong>Heads-up!</strong>
    You might want to checkout the <a href="http://www.camunda.org/">Getting Started Tutorial</a> first as it explaines the creation of a process application step by step.
  </p>
</div>

## The Process Application class<a id="the-process-application-class"></a>

You can deleagte the bootstrapping of the process engine and process deployment to a process application class. The basic ProcessApplication functionality is provided by the `org.camunda.bpm.application.AbstractProcessApplication` base class. Based on this class there is a set of environment-specific sub classes that realize integration within a specific environment:

* **ServletProcessApplication**: To be used for Process Applications is a Servlet Container like Apache Tomcat.
* **EjbProcessApplication**: To be used in a Java EE application server like JBoss, Glassfish or WebSphere Application Server.
* **EmbeddedProcessApplication**: To be used when embedding the process engine is an ordinary Java SE application.
* **SpringProcessApplication**: To be used for bootstrapping the process application from a Spring Application Context.

In the following, we walk through the different implementations and discuss where and how they can be used. 

### The ServletProcessApplication<a id="the-servlet-process-application"></a>
<div class="alert">
  <p>
    <strong>All Servlet Containers</strong>     
  </p>
    <span class="container-tiny tomcat"></span>
    <span class="container-tiny as7"></span>
    <span class="container-tiny glassfish"></span>

  <p>The Servlet Process Application is supported on all containers. Read the <a href="#servlet-process-applicarion-inside-ejb-container">note about Servlet Process Application and EJB / Java EE containers</a>.</p>
  <p><strong>Packaging</strong>: WAR (or embedded WAR inside EAR)</p>
</div>

The `ServletProcessApplication` class is the base class for developing Process Applications based on the Servlet Specification (Java Web Applications). The servlet process application implements the `javax.servlet.ServletContextListener` interface which allows it to participate in the deployment lifecycle of your Web application

The following is an example of a Servlet Process Application:

    package org.camunda.bpm.example.loanapproval;

    import org.camunda.bpm.application.ProcessApplication;
    import org.camunda.bpm.application.impl.ServletProcessApplication;

    @ProcessApplication("Loan Approval App")
    public class LoanApprovalApplication extends ServletProcessApplication {
      // empty implementation
    }

Notice the `@ProcessApplication` annotation. This annotation fulfills two purposes:

  * **providing the name of the ProcessApplication**: You can provide a custom name for you process application using the annotation: `@ProcessApplication("Loan Approval App")`. If no name is provided, a name is automatically detected. In case of a ServletProcessApplication, the name of the ServletContext is used.
  * **triggering auto-deployment**. In a Servlet 3.0 container, the annotation is sufficient for making sure that the process application is automatically picked up by the servlet container and automatically added as a ServletContextListener to the Servlet Container deployment. This functionality is realized by a `javax.servlet.ServletContainerInitializer` implementation named `org.camunda.bpm.application.impl.ServletProcessApplicationDeployer` which is located in the camunda-engine module. The implementation works for both embedded deployment of the camunda-engine.jar as a web application library in the `WEB-INF/lib` folder of your WAR file or for the deployment of the camunda-engine.jar as a shared library in the shared library (i.e. Apache Tomcat global `lib/` folder) directory of your application server. The Servlet 3.0 Specification foresees both deployment scenarios. In case of embedded deployment, the `ServletProcessApplicationDeployer` is notified once, when the webapplication is deployed. In case of deployment as a shared library, the `ServletProcessApplicationDeployer` is notified for each WAR file containing a class annotated with `@ProcessApplication` (as required by the Servlet 3.0 Specification).

This means that in case you deploy to a Servlet 3.0 compliant container (such as Apache Tomcat 7) annotating your class with `@ProcessApplication` is sufficient. 

#### Deploying to Apache Tomcat 6 or other Pre-Servlet 3.0 Containers

In a Pre-Servlet 3.0 container such as Apache Tomcat 6 (or JBoss Application Server 5 for that matter), you need manually register your ProcessApplication class as Servlet Context Listener in the Servlet Container. This can be achieved by adding a listener element to your `WEB-INF/web.xml` file:


    <?xml version="1.0" encoding="UTF-8"?>
    <web-app version="2.5" xmlns="http://java.sun.com/xml/ns/javaee"
             xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
             xsi:schemaLocation="http://java.sun.com/xml/ns/javaee    http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd">

      <listener>
        <listener-class>org.my.project.MyProcessApplication</listener-class>
      </listener>

    </web-app>    

<a name="servlet-process-applicarion-inside-ejb-container"></a>
#### Using the ServletProcessApplication inside an EJB / Java EE Container such as Glassfish or JBoss

You can use the ServletProcessApplication inside an EJB / Java EE Container such as Glassfish or JBoss. Process application bootstrapping and deployment will work in the same way. However, you will not be able to use all Java EE features at runtime. In contrast to the `EjbProcessApplication` (see next section), the `ServletProcessApplication` does not perform proper Java EE cross-application context switching. When the process engine invokes Java Delegates form your application, only the Context Class Loader of the current Thread is set to the classloader of your application. This does allow the process engine to resolve Java Deleagte implementations form your application but the container will not perform an EE context switch to your application. As a consequence, if you use the ServletProcessApplciation inside a Java EE container, you will not be able to use features like:

  * using CDI beans and EJBs as JavaDelegate Implementations in combination with the Job Executor,
  * using @RequestScoped CDI Beans with the Job Executor,
  * looking up JNDI resources from the application's naming scope

If your application does not use such features, it is perfectly fine using the ServletProcessApplication inside an EE container in that case you only get servlet specification guarantees.

### The EjbProcessApplication<a id="the-ejb-process-application"></a>
<div class="alert ">
  <p>
    <strong>Java EE 6 Container only</strong>     
  </p>
  <p>
    <span class="container-tiny as7"></span>
    <span class="container-tiny glassfish"></span>
  </p>
  <p>The EjbProcessApplication is supported in Java EE 6 containers or better. It is not supported on Servlet Containers like Apache Tomcat. It may be adapted to work inside Java EE 5 Containers.</p>  
  <p><strong>Packaging:</strong> JAR, WAR, EAR</p>
</div>

The EjbProcessApplication is the base class for developing Java EE based Process Applications. An Ejb Process Application class itself must be deployed as an EJB. 

In order to add an Ejb Process Application to your Java Application, you have two options:

  * **Bundling the camunda-ejb-client**: we provide a generic, reusable EjbProcessApplication implementation (named `org.camunda.bpm.application.impl.ejb.DefaultEjbProcessApplication`) bundled as a maven artifact. This simplest possibility is to add this implementation as a maven dependency to your application.
  * **Writing a custom EjbProcessApplication**: if you want to customize the behavior of the EjbProcessApplication, you can write a custom subclass of the EjbProcessApplication class and add it to your application.

Both options are explained in greater detail below.

#### Bundling the camunda-ejb-client Jar

The most convenient option for deploying a process application to an Ejb Container is adding the following maven dependency to you maven project:

    <dependency>
      <groupId>org.camunda.bpm.javaee</groupId>
      <artifactId>camunda-ejb-client</artifactId>
      <version>${camunda.version}</version>
    </dependency>

The camunda-ejb-client contains a reusable default implemenation of the EjbProcessApplicaiton as a Singleton Session Bean with auto-activation. 

This deployment option requires that your project is a composite deployment (such as a WAR or EAR) deployment since you need to add a library JAR file. You could of course use something like the maven shade plugin for adding the class contained in the camunda-ejb-client artifact to a JAR-based deployment. 

<div class="alert alert-info">
  We always recommend using the camunda-ejb-client over deploying a custom EjbProcessApplication class unless you want to customize the behavior of the EjbProcessApplication.
</div>

#### Deploying a custom EjbProcessApplication class

If you want to customize the behavior of the the EjbProcessApplication class you have to option of writing a custom EjbProcessApplication class. The following is an example of such an implementation:

    @Singleton
    @Startup
    @ConcurrencyManagement(ConcurrencyManagementType.BEAN) 
    @TransactionAttribute(TransactionAttributeType.REQUIRED)
    @ProcessApplication
    @Local(ProcessApplicationInterface.class)
    public class MyEjbProcessApplication extends EjbProcessApplication {
      
      @PostConstruct
      public void start() {
        deploy();
      }

      @PreDestroy
      public void stop() {
        undeploy();
      }
        
    }

#### Invocation Semantics of  the EjbProcessApplication

The fact that the EjbProcessApplication exposes itself as a Session Bean Component inside the EJB container 

 * determines the invocation semantics when invoking code from the process application and
 * the nature of the `ProcessApplicationReference` held by the process engine.

When the process engine invokes the Ejb Process Application, it gets EJB invocation semantics. For example, if your process application provides a `JavaDelegate` implementation, the process engine will call the EjbProcessApplication's `execute(java.util.concurrent.Callable)` method and from that method invoke `JavaDelegate`. This makes sure that 

  * the call is intercepted by the EJB container and "enters" the process application legally.
  * the `JavaDelegate` may take advantage of the EjbProcessApplication's invocation context and resolve resources from the component's environment (such as a `java:comp/BeanManager`).
 
<pre>
                   Big pile of EJB interceptors
                                |
                                |  +--------------------+    
                                |  |Process Application |
                  invoke        v  |                    |
 ProcessEngine ----------------OOOOO--> Java Delegate   |
                                   |                    |
                                   |                    |
                                   +--------------------+
</pre>

When the EjbProcessApplication registers with a process engine (see `ManagementService#registerProcessApplication(String, ProcessApplicationReference)`, the process application passes a reference to itself to the process engine. This reference allows the process engine to reference the process application. The EjbProcessApplication takes advantage of the Ejb Containers naming context and passes a reference containing the EJBProcessApplication's Component Name to the process engine. Whenever the process engine needs access to process application, the actual component instance is looked up and invoked.

### The EmbeddedProcessApplication<a id="the-embedded-process-application"></a>
<div class="alert ">
  <p>
    <strong>All containers</strong>     
  </p>
  <p>
    <span class="container-tiny jvm"></span>
    <span class="container-tiny tomcat"></span>
    <span class="container-tiny as7"></span>
    <span class="container-tiny glassfish"></span>
  </p>
  <p>The EmbeddedProcessApplication can only be used with an embedded process engine and does not provide 
  auto-activation.</p>  
  <p><strong>Packaging:</strong> JAR, WAR, EAR</p>
</div>

The `org.camunda.bpm.application.impl.EmbeddedProcessApplication` can only be used in combination with an embedded process engine. Usage in combination with a Shared Process Engine is not supported as the class performs no process application context switching at runtime.

The Embedded Process Application does also not provide auto-startup. You need to manually call the deploy method of your process application:

    // instantiate the process application
    MyProcessApplication processApplication = new MyProcessApplication();

    // deploy the process application
    processApplication.deploy();

    // interact with the process engine
    ProcessEngine processEngine = BpmPlatform.getDefaultProcessEngine();
    processEngine.getRuntimeService().startProcessInstanceByKey(...);
    
    // undeploy the process application
    processApplication.undeploy();

Where the class `MyProcessApplication` could look like this:

    @ProcessApplication(
        name="my-app",
        deploymentDescriptors={"path/to/my/processes.xml"}
    )
    public class MyProcessApplication extends EmbeddedProcessApplication {

    }

### The SpringProcessApplication<a id="the-spring-process-application"></a>
<div class="alert ">
  <p>
    <strong>Supported on</strong>     
  </p>
  <p>
    <span class="container-tiny jvm"></span>
    <span class="container-tiny tomcat"></span>
    <span class="container-tiny glassfish"></span>
  </p>
  <p>The spring process application is currently <strong>not supported on JBoss AS 7</strong>.</p>  
  <p><strong>Packaging:</strong> JAR, WAR, EAR</p>
</div>

The `org.camunda.bpm.engine.spring.application.SpringProcessApplication` class allows bootstrapping a process application through a Spring Application Context. You can either reference the SpringProcessApplication class from an Xml-based application context configuration file or use annotation-based setup. 

If your application is a WebApplicaiton you should use `org.camunda.bpm.engine.spring.application.SpringServletProcessApplication` as it provides support for exposing the servlet context path through the `ProcessApplicationInfo#PROP_SERVLET_CONTEXT_PATH` property. 
 
<div class="alert alert-info">
  <strong>SpringServletProcessApplication</strong>
  <p>We recommend always using SpringServletProcessApplication unless the deployment is not a web application. Using this class requires the 
  <code>org.springframework:spring-web</code> module to be on the classpath.</p>
</div>

#### Configuring a Spring Process Application

The following shows an example of how to bootstrap a SpringProcessApplication inside a spring application context Xml file:

    <beans xmlns="http://www.springframework.org/schema/beans"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           xsi:schemaLocation="http://www.springframework.org/schema/beans   
                               http://www.springframework.org/schema/beans/spring-beans.xsd">

      <bean class="org.camunda.bpm.engine.spring.application.SpringServletProcessApplication" />
        
    </beans>

(Remember that you need a `META-INF/processes.xml` file, additionally).

#### Configuring a Managed Process Engine using Spring

If you use a Spring Process Application, you may want to configure your process engine inside the spring application context Xml file (as opposed to the processes.xml file). In this case, you must use the `org.camunda.bpm.engine.spring.container.ManagedProcessEngineFactoryBean` class for creating the process engine object instance. In addition to creating the process engine object, this implementation registers the process engine with the BPM Platform infrastructure such that the process engine is returned by the `ProcessEngineService`. The following is an example of how to configure a managed process engine using Spring.

    <beans xmlns="http://www.springframework.org/schema/beans"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
           xsi:schemaLocation="http://www.springframework.org/schema/beans   
                               http://www.springframework.org/schema/beans/spring-beans.xsd">
           
        <bean id="dataSource" class="org.springframework.jdbc.datasource.TransactionAwareDataSourceProxy">
            <property name="targetDataSource">
                <bean class="org.springframework.jdbc.datasource.SimpleDriverDataSource">
                    <property name="driverClass" value="org.h2.Driver"/>
                    <property name="url" value="jdbc:h2:mem:activiti;DB_CLOSE_DELAY=1000"/>
                    <property name="username" value="sa"/>
                    <property name="password" value=""/>
                </bean>
            </property>
        </bean>

        <bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
            <property name="dataSource" ref="dataSource"/>
        </bean>

        <bean id="processEngineConfiguration" class="org.camunda.bpm.engine.spring.SpringProcessEngineConfiguration">
            <property name="processEngineName" value="default" />
            <property name="dataSource" ref="dataSource"/>
            <property name="transactionManager" ref="transactionManager"/>
            <property name="databaseSchemaUpdate" value="true"/>
            <property name="jobExecutorActivate" value="false"/>
        </bean>

        <!-- using ManagedProcessEngineFactoryBean allows registering the ProcessEngine with the BpmPlatform -->
        <bean id="processEngine" class="org.camunda.bpm.engine.spring.container.ManagedProcessEngineFactoryBean">
            <property name="processEngineConfiguration" ref="processEngineConfiguration"/>
        </bean>
        
        <bean id="repositoryService" factory-bean="processEngine" factory-method="getRepositoryService"/>
        <bean id="runtimeService" factory-bean="processEngine" factory-method="getRuntimeService"/>
        <bean id="taskService" factory-bean="processEngine" factory-method="getTaskService"/>
        <bean id="historyService" factory-bean="processEngine" factory-method="getHistoryService"/>
        <bean id="managementService" factory-bean="processEngine" factory-method="getManagementService"/>
            
    </beans>

## The processes.xml deployment descriptor<a id="the-processes-xml-deployment-descriptor"></a>

The processes.xml deployment descriptor contains the deployment metadata for a process application. The following example is a simple example of a `processes.xml` deployment descriptor: 

    <process-application
      xmlns="http://www.camunda.org/schema/1.0/ProcessApplication"
      xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">

      <process-archive name="loan-approval">
        <process-engine>default</process-engine>
        <properties>
          <property name="isDeleteUponUndeploy">false</property>
          <property name="isScanForProcessDefinitions">true</property>
        </properties>
      </process-archive>

    </process-application>

A single deployment (process-archive) is declared. The process archive has the name *loan-approval* and is deployed to the process engine with the name *default*. Two additional properties are specified:

  * `isDeleteUponUndeploy`: this property controls whether the undeployment of the process application should entail that the process engine deployment is deleted from the database. The default setting is false. If this property is set to true, undeployment of the process application leads to the removal of the deplyoment (including process instances) from the database. 
  * `isScanForProcessDefinitions`: if this property is set to true, the classpath of the process application is automatically scanned for process definition resources. Process definition resources must end in `.bpmn20.xml` or `.bpmn`.

### Location of the processes.xml file<a id="processes-xml-location"></a>

The default location of the processes.xml file is `META-INF/processes.xml`. The camunda BPM platform will parse and process all processes.xml files on the classpath of a process application. Composite process applications (WAR / EAR) may carry multiple subdeployments providing a META-INF/processes.xml file.

In an apache maven based project, add the the processes.xml file to the `src/main/resources/META-INF` folder.

### Custom location for the processes.xml file<a id="processes-xml-custom-location"></a>

If you want to specify a custom location for the processes.xml file, you need to use the `deploymentDescriptors` property of the `@ProcessApplication` annotation:

    @ProcessApplication(
        name="my-app",
        deploymentDescriptors={"path/to/my/processes.xml"}
    )
    public class MyProcessApp extends ServletProcessApplication {

    }

The provided path(s) must be resolvable through the `ClassLoader#getResourceAsStream(String)`-Method of the classloader returned  by the `AbstractProcessApplication#getProcessApplicationClassloader()` method of the process application.

Multiple distinct locations are supported.

### Configuring process engines in the processes.xml file<a id="processes-xml-configuring-process-engines"></a>

The processes.xml file can also be used for configuring one or multiple process engine(s). The following is an example of a configuration of a process engine inside a processes.xml file:

    <process-application
    xmlns="http://www.camunda.org/schema/1.0/ProcessApplication"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">

      <process-engine name="my-engine">
        <configuration>org.camunda.bpm.engine.impl.cfg.StandaloneInMemProcessEngineConfiguration</configuration>        
      </process-engine>

      <process-archive name="loan-approval">
        <process-engine>my-engine</process-engine>
        <properties>
          <property name="isDeleteUponUndeploy">false</property>
          <property name="isScanForProcessDefinitions">true</property>
        </properties>
      </process-archive>

    </process-application>

The `<configuration>...</configuration>` property allows specifying the name of a process engine configuration class to be used when building the process engine.

## Migration from camunda fox 6.x<a id="migration-from-camunda-fox-6x"></a>

<div class="alert">
    <strong>Note that the Process Application logic has slightly changed from camunda fox 6.x (the predecessor to camunda BPM 7.0), you need to migrate your applications.</strong>
    Please follow the instructions in the <a href="<%= @docUrl('guides/migration-guide/index.html') %>">Activiti Migration Guide</a> which contains a section about camunda fox at the end.
</div>


# Runtime Container Integration<a id="bpmplatform/container"></a>

## JNDI Bindings for BPM Platform Services<a id="bpmplatform/container/jndi/platform-services"></a>

The BPM Platform Services (i.e. Process Engine Service and Process Application Service) are provided via JNDI Bindings with the following JNDI names:

* Process Engine Service: `java:global/camunda-bpm-platform/process-engine/ProcessEngineService!org.camunda.bpm.ProcessEngineService`
* Process Application Service: `java:global/camunda-bpm-platform/process-engine/ProcessApplicationService!org.camunda.bpm.ProcessApplicationService`

On Glassfish 3.1.1 and on JBoss AS 7 you can do a lookup with the JNDI names to get one of these BPM Platform Services. However, on Apache Tomcat 7 you have to do quite more to be able to do a lookup to get one of these BPM Platform Services.

## JNDI Bindings on Apache Tomcat 7<a id="bpmplatform/container/jndi/platform-services-tomcat-7"></a>

To use the JNDI Bindings for Bpm Platform Services on Apache Tomcat 7 you have to add in your process application the file `META-INF/context.xml` and add the following [ResourceLinks](http://tomcat.apache.org/tomcat-7.0-doc/config/context.html#Resource_Links):

	<Context>
		<ResourceLink name="ProcessEngineService"
		        global="global/camunda-bpm-platform/process-engine/ProcessEngineService!org.camunda.bpm.ProcessEngineService"
		        type="org.camunda.bpm.ProcessEngineService" />
		        
		<ResourceLink name="ProcessApplicationService"
		        global="global/camunda-bpm-platform/process-engine/ProcessApplicationService!org.camunda.bpm.ProcessApplicationService"
		        type="org.camunda.bpm.ProcessApplicationService" />
	</Context>

These elements are used to create a link to the global JNDI Resources definied in `$CATALINA_HOME/conf/server.xml`.

Furthermore, declare the dependency on the JNDI binding inside the `WEB-INF/web.xml` deployment descriptor.

	<web-app>
		<resource-ref>
			<description>Process Engine Service</description>
			<res-ref-name>ProcessEngineService</res-ref-name>
			<res-type>org.camunda.bpm.ProcessEngineService</res-type> 
			<res-auth>Container</res-auth>
			</resource-ref>

		<resource-ref>
			<description>Process Application Service</description>
			<res-ref-name>ProcessApplicationService</res-ref-name>
			<res-type>org.camunda.bpm.ProcessApplicationService</res-type> 
			<res-auth>Container</res-auth>
		</resource-ref>
		...
	</web-app>

**Note**: You can choose different resource link names for the Process Engine Service and Process Application Service. The resource link name has to match with the value inside the `<res-ref-name>`-element inside the correspondig `<resource-ref>`-element in `WEB-INF/web.xml`. We propose the name `ProcessEngineService` for the Process Engine Service and `ProcessApplicationService` for the Process Application Service.

In order to do a lookup for a Bpm Platform Service you have to use the resource link name to get the linked global resource. For example:

* Process Engine Service: `java:comp/env/ProcessEngineService`
* Process Application Service: `java:comp/env/ProcessApplicationService`

If you have declared another resource link names than we proposed, you have to use `java:comp/env/$YOUR_RESOURCE_LINK_NAME` to do a lookup to get the corresponding Bpm Platform Service.

## The camunda JBoss AS 7 Subsystem<a id="bpmplatform/container/jboss"></a>

<div class="alert alert-info">
  <p>
    <strong>Distribution & Installation Guide</strong>     
  </p>
   <p>If you <a href="http://www.camunda.org/download/">download a pre-packaged distribution from camunda.org</a>, the camunda JBoss Subsystem is readily installed into the application server</p>
   <p><a href="/guides/installation-guide/jboss/">Read the installation guide</a> in order to learn how to install the camunda JBoss subsystem into your JBoss Server.</p>
</div>

camunda BPM provides advanced integration for JBoss Application Server 7 in the form of a custom <a href="https://docs.jboss.org/author/display/AS71/Extending+JBoss+AS+7">JBoss AS 7 Subsystem</a>. 

The most prominent features are:

* Deploy the process engine as shared jboss module.
* Configure the process engine in standalone.xml / domain.xml and administer it though the JBoss Management System.
* Process Engines are native JBoss Services with service lifecycle and dependencies.
* Automatic deployment of BPMN 2.0 processes (through the Process Application API).
* Use a managed Thread Pool provided by JBoss Threads in combination with the Job Executor.

### Configuring a process engine in standalone.xml / domain.xml<a id="bpmplatform/container/jboss/config"></a>

Using the camunda JBoss AS 7 Subsystem, it is possible to configure and manage the process engine through the JBoss Management Model. The most straight forward way is to add the process engine configuration to the `standalone.xml` file of the JBoss Server:

    <subsystem xmlns="urn:org.camunda.bpm.jboss:1.1">
        <process-engines>
            <process-engine name="default" default="true">
                <datasource>java:jboss/datasources/ProcessEngine</datasource>
                <history-level>full</history-level>
                <properties>
                    <property name="jobExecutorAcquisitionName">default</property>
                    <property name="isAutoSchemaUpdate">true</property>
                    <property name="authorizationEnabled">true</property>
                </properties>
            </process-engine>
        </process-engines>
        <job-executor>
            <thread-pool-name>job-executor-tp</thread-pool-name>
            <job-acquisitions>
                <job-acquisition name="default">
                    <acquisition-strategy>SEQUENTIAL</acquisition-strategy>
                    <properties>
                        <property name="lockTimeInMillis">300000</property>
                        <property name="waitTimeInMillis">5000</property>
                        <property name="maxJobsPerAcquisition">3</property>
                    </properties>
                </job-acquisition>
            </job-acquisitions>
        </job-executor>
    </subsystem>

It should be easy to see that the configuration consists of a single process engine which uses the Datasource `java:jboss/datasources/ProcessEngine` and is configured to be the `default` process engine. In addition, the Job Executor currently uses a single Job Acquisition also named default.

If you start up your JBoss AS 7 server with this configuration, it will automatically create the corresponding services and expose them through the management model. 

### Providing a custom process engine configuration class<a id="bpmplatform/container/jboss/custom-config"></a>
It is possible to provide a custom Process Engine Configuration class on JBoss AS 7. To this extend, provide the fully qualified classname of the class in the `standalone.xml` file:

    <process-engine name="default" default="true">
        <datasource>java:jboss/datasources/ProcessEngine</datasource>
        <configuration>org.my.custom.ProcessEngineConfiguration</configuration>
        <history-level>full</history-level>
        <properties>
            <property name="myCustomProperty">true</property>
            <property name="lockTimeInMillis">300000</property>
            <property name="waitTimeInMillis">5000</property>
        </properties>
    </process-engine>

The class `org.my.custom.ProcessEngineConfiguration` must be a subclass of `org.camunda.bpm.engine.impl.cfg.JtaProcessEngineConfiguration`.

The properties map can be used for invoking primitive valued setters (Integer, String, Boolean) that follow the Java Bean conventions. In the case of the example above, the
class would provide a method named

    public void setMyCustomProperty(boolean boolean) {
      ...
    }

<div class="alert">
  <p>
    <strong>Module dependency of custom configuration class</strong>     
  </p>
   <p>If you configure the process engine in `standalone.xml` and provide a custom configuration class packaged inside an own module, the camunda-jboss-subsystem module needs to have a module dependency on the module providing the class.</p>
   <p>If you fail to do this, you will see the following error log:</p>
   <pre class="console">
Caused by: org.camunda.bpm.engine.ProcessEngineException: Could not load 'foo.bar': the class must be visible from the camunda-jboss-subsystem module.
        at org.camunda.bpm.container.impl.jboss.service.MscManagedProcessEngineController.createProcessEngineConfiguration(MscManagedProcessEngineController.java:187) [camunda-jboss-subsystem-7.0.0-alpha8.jar:]
        at org.camunda.bpm.container.impl.jboss.service.MscManagedProcessEngineController.startProcessEngine(MscManagedProcessEngineController.java:138) [camunda-jboss-subsystem-7.0.0-alpha8.jar:]
        at org.camunda.bpm.container.impl.jboss.service.MscManagedProcessEngineController$3.run(MscManagedProcessEngineController.java:126) [camunda-jboss-subsystem-7.0.0-alpha8.jar:]
</pre>

</div>

### Looking up a Process Engine in JNDI<a id="bpmplatform/container/jboss/jndi"></a>
The camunda JBoss subsystem provides the same [JNDI bindings for the ProcessApplicationService and the ProcessEngineService](#!/#bpmplatform/container/jndi/platform-services) as provided on other containers. In addition, the camunda JBoss subsystem creates JNDI Bindings for all managed process engines, allowing us to look them up directly. 

The global JNDI bindings for process engines follow the pattern

    java:global/camunda-bpm-platform/process-engine/$PROCESS_ENGINE_NAME

If a process engine is named "engine1", it will be available using the name `java:global/camunda-bpm-platform/process-engine/engine1`.

Note that when looking up the process engine, using a declarative mechanism (like `@Resource` or referencing the resource in a deployment descriptor) is preferred over a programmatic way. The declarative mechanism makes the application server aware of our dependency on the process engine service and allows it to manage that dependency for us. See also: [Managing Service Dependencies](#!/#bpmplatform/container/jboss/services/explicit).

<div class="alert">
  <p>
    <strong>Looking up a Process Engine from JNDI using Spring</strong>     
  </p>
   <p>On JBoss AS 7, spring users should always [create a resource-ref for the process engine in web.xml](#!/#bpmplatform/container/jboss/services) and then lookup the local name in the `java:comp/env/` namespace. <a href="https://github.com/camunda/camunda-quickstarts/tree/master/deployment/spring-jboss-non-pa">For an example, see this Quickstart</a>.</p>
</div>

### Managing the process engine through the JBoss Management System<a id="bpmplatform/container/jboss/management"></a>

In oder to inspect and change the management model, we can use <a href="https://docs.jboss.org/author/display/AS72/Management+Clients">one of the multiple JBoss Management clients available</a>. 


#### Inspecting the configuration

It is possible to inspect the configuration using the CLI (Command Line Interface, jboss-cli.bat/sh):

<pre class="console">
You are disconnected at the moment. Type 'connect' to connect to the server or 'help' for the list of supported commands.
[disconnected /] connect
[standalone@localhost:9999 /] cd /subsystem=camunda-bpm-platform
[standalone@localhost:9999 subsystem=camunda-bpm-platform] :read-resource(recursive=true)
{
    "outcome" => "success",
    "result" => {
        "job-executor" => {"default" => {
            "thread-pool-name" => "job-executor-tp",
            "job-acquisitions" => {"default" => {
                "acquisition-strategy" => "SEQUENTIAL",
                "name" => "default",
                "properties" => {
                    "lockTimeInMillis" => "300000",
                    "waitTimeInMillis" => "5000",
                    "maxJobsPerAcquisition" => "3"
                }
            }}
        }},
        "process-engines" => {"default" => {
            "configuration" => "org.camunda.bpm.container.impl.jboss.config.ManagedJtaProcessEngineConfiguration",
            "datasource" => "java:jboss/datasources/ProcessEngine",
            "default" => true,
            "history-level" => "full",
            "name" => "default",
            "properties" => {
                "jobExecutorAcquisitionName" => "default",
                "isAutoSchemaUpdate" => "true"
            }
        }}
    }
}
</pre>

#### Stopping a Process Engine through the JBoss Management System

Once the process engine is registered in the JBoss Management Model, it is possible to control it thorough the management API. For example, you can stop it through the CLI:

<pre class="console">
[standalone@localhost:9999 subsystem=camunda-bpm-platform] cd process-engines=default
[standalone@localhost:9999 process-engines=default] :remove
{"outcome" => "success"}
</pre>

This removes the process engine and all dependent services. This means that if you remove a process engine the application server will stop all deployed applications which use the process engine. 

<div class="alert">
  <p>
    <strong>Declaring Service Dependencies</strong>     
  </p>
   <p>In order for this to work, but also in order to avoid race conditions at deployment time, it is necessary that each application explicitly declares dependencies on the process engines it is using. <a href="">Learn how to declare dependencies</a></p>
</div>

#### Starting a Process Engine through the JBoss Management System

It is also possible to start a new process engine at runtime: 
<pre class="console">
[standalone@localhost:9999 subsystem=camunda-bpm-platform] /subsystem=camunda-bpm-platform/process-engines=my-process-engine/:add(name=my-process-engine,datasource=java:jboss/datasources/ExampleDS)
{"outcome" => "success"}
</pre>

One of the nice features of the JBoss AS 7 Management System is that it will 

* persist any changes to the model in the underlying configuration file. This means that if you start a process engine using the command line interface, the configuration will be added to `standalone.xml` / `domain.xml` such that it is available when the server is restarted.
* distribute the configuration in the cluster and start / stop the process engine on all servers part of the same domain.

#### Using the JBoss JConsole Extensions

In some cases, you may find it more convenient to use the JBoss JConsole extension for starting a process engine. 

<center><img src="assets/img/jboss-jconsole.png"></img></center>

The JConsole plugin allows you to inspect the management model graphically and build operations using a wizard. In order to start the JBoss JConsole plugin, start the jconsole.bat/sh file provided in the JBoss distribution. <a href="https://docs.jboss.org/author/display/AS72/JMX+subsystem+configuration">More Information in the JBoss Docs</a>.

### Managing Classpath Dependencies<a id="bpmplatform/container/jboss/classpath"></a>

<div class="alert alert-info">
  <p>
    <strong>Implicit module dependencies</strong>     
  </p>
   <p>Classpath dependencies are automatically managed for you if you use the <a href="#process-applications">Process Application API</a>.</p>
</div>

When using the camunda BPM JBoss AS subsystem, the process engine classes are deployed as jboss module. The module is named 
`org.camunda.bpm.process-engine` and is deployed in the folder `$JBOSS_HOME/modules/org/camunda/bpm/camunda-engine`.

By default, the Application server will not add this module to the classpath of applicaitons.If an application needs to interact with the process engine, we must declare a module dependency in the application. This can be achieved using either an implicit or an explicit module dependency.

#### Implicit module dependencies with the Process Application API<a id="bpmplatform/container/jboss/classpath/implicit"></a>
When using the Process Application API (ie. when deploying either a <a href="#the-servlet-process-application">ServletProcessApplication</a> or an <a href="#the-ejb-process-application">EjbProcessApplication</a>), the camunda JBoss Subsystem will detect the `@ProcessApplication` class in the deployment and automatically add a module dependency between the application and the process engine module. As a result, we don't have to declare the dependency ourselves. It is called an <a href="https://docs.jboss.org/author/display/AS72/Implicit+module+dependencies+for+deployments">implicit module dependency</a> because it is not explicitly declared but can be derived by inspecting the application and seeing that it provides a `@ProcessApplication` class.

#### Explicit module dependencies<a id="bpmplatform/container/jboss/classpath/explicit"></a>
If an application does not use the process application API but still needs the process engine classes to be added to its classpath, an explicit module dependency is required.
JBoss AS 7 has <a href="https://docs.jboss.org/author/display/AS72/Class+Loading+in+AS7">different mechanisms for achieving this</a>. The simplest way is to add a manifest entry to the MANIFEST.MF file of the deployment. The following example illustrates how to generate such a dependency using the maven WAR plugin:

    <build>
       ...
       <plugins>
         <plugin>
           <groupId>org.apache.maven.plugins</groupId>
           <artifactId>maven-war-plugin</artifactId>
           <configuration>
              <archive>
                 <manifestEntries>
                    <Dependencies>org.camunda.bpm.process-engine</Dependencies>
                 </manifestEntries>
              </archive>
           </configuration>
         </plugin>
       </plugins>
    </build>

As a result, the Application Service will add the process engine module to the classpath of the application.

### Managing Service Dependencies<a id="bpmplatform/container/jboss/services"></a>

<div class="alert alert-info">
  <p>
    <strong>Implicit service dependencies</strong>     
  </p>
   <p>Service dependencies are automatically managed for you if you use the <a href="#process-applications">Process Application API</a>.</p>
</div>

The camunda JBoss subsystem manages process engines as JBoss Services in the JBoss Module Service Container. In order for the Module Service Container to provide the process engine service(s) to the deployed applications, it is important that the dependencies are known. Consider the following example:

<center><img src="assets/img/jboss-service-dependencies.png"></img></center>

There are three applications deployed and two process engine services exist. Application 1 and Application 2 are using Process Engine 1 and Application 3 is using Process Engine 2. 

#### Implicit Service Dependencies<a id="bpmplatform/container/jboss/services/implicit"></a>

When using the Process Application API (ie. when deploying either a <a href="#the-servlet-process-application">ServletProcessApplication</a> or an <a href="#the-ejb-process-application">EjbProcessApplication</a>), the camunda JBoss Subsystem will detect the `@ProcessApplication` class in the deployment and automatically add a service dependency between the process application component and the process engine module. This makes sure the process engine is available when the process application is deployed.

#### Explicit Service Dependencies<a id="bpmplatform/container/jboss/services/explicit"></a>

If an application does not use the process application API but still needs to interact with a process engine, it is important to declare the dependency on the process engine service explicitly. If we fail to declare the dependency, there is no guarantee that the process engine is available to the application. 

* When the application server is started, it will bring up services concurrently. If it is not aware of the dependency between the application and the process engine, the application may start *before* the process engine, potentially resulting in exceptions if the process engine is accessed from some deployment listener (like a servlet context listener or a @PostConstruct callback of an Enterprise Bean).
* If the process engine is stopped while the application is deployed, the application server must stop the application as well.

The simplest way to add an explicit dependency on the process engine is to bind the process engine in application's local naming space. For instance, we can add the following resource reference to the `web.xml` file of a web application:

    <resource-ref>
      <res-ref-name>processEngine/default</res-ref-name>   
      <res-type>org.camunda.bpm.engine.ProcessEngine</res-type>
      <mapped-name>java:global/camunda-bpm-platform/process-engine/default</mapped-name>    
    </resource-ref>

This way, the global process engine resource `java:global/camunda-bpm-platform/process-engine/default` is available locally under the name `processEngine/default`. Since the application server is aware of this dependency, it will make sure the process engine service exists before starting the application and it will stop the application if the process engine is removed. 

The same effect can be achieved using the @Resource Annotation:

    @Stateless
    public class PaComponent {
      
      @Resource(mappedName="java:global/camunda-bpm-platform/process-engine/default")
      private ProcessEngine processEngine;
      
      @Produces
      public ProcessEngine getProcessEngine() {
        return processEngine;
      }

    }

## Integrating the camunda BPM platform into different Environments<a id="camunda-bpm-platform-integration"></a>